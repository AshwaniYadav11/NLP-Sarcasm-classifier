{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SARCASM DETECTOR PROJECT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6b7Q8MC4SXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2fae604a-9e2b-4f84-9526-0fd82f0872db"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json\n",
        "  \n",
        "import json\n",
        "\n",
        "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
        "    data = json.load(f)\n",
        "sent=[]\n",
        "is_sar=[]\n",
        "url=[]\n",
        "\n",
        "for head in data:\n",
        "  sent.append(head['headline'])\n",
        "  is_sar.append(head['is_sarcastic'])\n",
        "  url.append(head['article_link'])\n",
        "\n",
        "print(sent[10])  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-03 19:03:29--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.217.203.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-09-03 19:03:29 (139 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n",
            "airline passengers tackle man who rushes cockpit in bomb threat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hed_TzlhShda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20b999bb-d39d-4836-f7cc-01f8244947d0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow as tf\n",
        "t=Tokenizer(oov_token='<OOV>')\n",
        "t.fit_on_texts(sent)\n",
        "word_index=t.word_index\n",
        "seq=t.texts_to_sequences(sent)\n",
        "pad=pad_sequences(seq,padding='post')\n",
        "\n",
        "print(len(pad[10]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRluh_SZXrnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7544dfaa-d388-4a06-ee28-1b534a93ff02"
      },
      "source": [
        "vocab_size=10000\n",
        "embedding_dim=16\n",
        "max_length=32\n",
        "trunc_type='post'\n",
        "oov_tok='<OOV>'\n",
        "training_size=20000\n",
        "\n",
        "training_sent=sent[0:training_size]\n",
        "test_sent=sent[training_size:]\n",
        "training_label=is_sar[0:training_size]\n",
        "test_label=is_sar[training_size:]\n",
        "print('Training Size: ',len(training_sent),\" and \",\"Testing size: \",len(test_sent))\n",
        "print(training_sent[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Size:  20000  and  Testing size:  6709\n",
            "former versace store clerk sues over secret 'black code' for minority shoppers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-I1x2VzZduY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "21a85aba-ab00-4a88-9ff5-6bc7d3765c7e"
      },
      "source": [
        "# tokenizing and padding testing and training data\n",
        "\n",
        "token=Tokenizer(num_words=vocab_size,oov_token=oov_tok)\n",
        "token.fit_on_texts(training_sent)\n",
        "wi=token.word_index\n",
        "training_seq=token.texts_to_sequences(training_sent)\n",
        "print(training_sent[0],training_seq[0])\n",
        "\n",
        "token.fit_on_texts(test_sent)\n",
        "training_pad=pad_sequences(training_seq,maxlen=max_length,padding='post',truncating='post')\n",
        "\n",
        "test_seq=token.texts_to_sequences(test_sent)\n",
        "test_pad=pad_sequences(test_seq,maxlen=max_length,truncating='post')\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "former versace store clerk sues over secret 'black code' for minority shoppers [328, 1, 799, 3405, 2404, 47, 389, 2214, 1, 6, 2614, 8863]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMxbD2Ese4NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#embedding is the means by which our model understand the sentiments of the word which are quite obvious for us through treaating each word as a vector\n",
        "\n",
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=max_length),\n",
        "     tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(24,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKtC_4f-hrBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "training_pad=np.array(training_pad)\n",
        "\n",
        "training_label=np.array(training_label)\n",
        "test_pad=np.array(test_pad)\n",
        "test_label=np.array(test_label)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ioyIaYGg3sT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2325de7e-7559-471a-97c5-ffeb2e127be0"
      },
      "source": [
        "hist=model.fit(training_pad,training_label,epochs=30,validation_data=(test_pad,test_label),verbose=2)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "625/625 - 2s - loss: 0.6389 - accuracy: 0.6288 - val_loss: 0.5879 - val_accuracy: 0.6727\n",
            "Epoch 2/30\n",
            "625/625 - 3s - loss: 0.4164 - accuracy: 0.8237 - val_loss: 0.6665 - val_accuracy: 0.6684\n",
            "Epoch 3/30\n",
            "625/625 - 3s - loss: 0.3438 - accuracy: 0.8566 - val_loss: 0.7332 - val_accuracy: 0.6493\n",
            "Epoch 4/30\n",
            "625/625 - 2s - loss: 0.2962 - accuracy: 0.8798 - val_loss: 0.8129 - val_accuracy: 0.6378\n",
            "Epoch 5/30\n",
            "625/625 - 2s - loss: 0.2744 - accuracy: 0.8875 - val_loss: 0.8800 - val_accuracy: 0.6278\n",
            "Epoch 6/30\n",
            "625/625 - 2s - loss: 0.2535 - accuracy: 0.8984 - val_loss: 0.9392 - val_accuracy: 0.6230\n",
            "Epoch 7/30\n",
            "625/625 - 2s - loss: 0.2420 - accuracy: 0.9052 - val_loss: 0.9710 - val_accuracy: 0.6221\n",
            "Epoch 8/30\n",
            "625/625 - 2s - loss: 0.2281 - accuracy: 0.9084 - val_loss: 1.0183 - val_accuracy: 0.6148\n",
            "Epoch 9/30\n",
            "625/625 - 2s - loss: 0.2172 - accuracy: 0.9162 - val_loss: 1.0597 - val_accuracy: 0.6110\n",
            "Epoch 10/30\n",
            "625/625 - 2s - loss: 0.2093 - accuracy: 0.9143 - val_loss: 1.0931 - val_accuracy: 0.6122\n",
            "Epoch 11/30\n",
            "625/625 - 2s - loss: 0.1997 - accuracy: 0.9226 - val_loss: 1.1291 - val_accuracy: 0.6074\n",
            "Epoch 12/30\n",
            "625/625 - 2s - loss: 0.1993 - accuracy: 0.9214 - val_loss: 1.1539 - val_accuracy: 0.6028\n",
            "Epoch 13/30\n",
            "625/625 - 2s - loss: 0.1918 - accuracy: 0.9245 - val_loss: 1.1806 - val_accuracy: 0.6016\n",
            "Epoch 14/30\n",
            "625/625 - 2s - loss: 0.1887 - accuracy: 0.9264 - val_loss: 1.1925 - val_accuracy: 0.6028\n",
            "Epoch 15/30\n",
            "625/625 - 2s - loss: 0.1822 - accuracy: 0.9286 - val_loss: 1.2228 - val_accuracy: 0.5973\n",
            "Epoch 16/30\n",
            "625/625 - 2s - loss: 0.1763 - accuracy: 0.9299 - val_loss: 1.2515 - val_accuracy: 0.5982\n",
            "Epoch 17/30\n",
            "625/625 - 2s - loss: 0.1774 - accuracy: 0.9299 - val_loss: 1.2485 - val_accuracy: 0.5984\n",
            "Epoch 18/30\n",
            "625/625 - 2s - loss: 0.1705 - accuracy: 0.9319 - val_loss: 1.3005 - val_accuracy: 0.5959\n",
            "Epoch 19/30\n",
            "625/625 - 2s - loss: 0.1659 - accuracy: 0.9348 - val_loss: 1.3121 - val_accuracy: 0.5938\n",
            "Epoch 20/30\n",
            "625/625 - 2s - loss: 0.1622 - accuracy: 0.9354 - val_loss: 1.3508 - val_accuracy: 0.5941\n",
            "Epoch 21/30\n",
            "625/625 - 2s - loss: 0.1648 - accuracy: 0.9361 - val_loss: 1.3376 - val_accuracy: 0.5906\n",
            "Epoch 22/30\n",
            "625/625 - 2s - loss: 0.1591 - accuracy: 0.9371 - val_loss: 1.3653 - val_accuracy: 0.5891\n",
            "Epoch 23/30\n",
            "625/625 - 2s - loss: 0.1554 - accuracy: 0.9416 - val_loss: 1.3853 - val_accuracy: 0.5926\n",
            "Epoch 24/30\n",
            "625/625 - 2s - loss: 0.1589 - accuracy: 0.9394 - val_loss: 1.3736 - val_accuracy: 0.5904\n",
            "Epoch 25/30\n",
            "625/625 - 2s - loss: 0.1574 - accuracy: 0.9355 - val_loss: 1.4116 - val_accuracy: 0.5904\n",
            "Epoch 26/30\n",
            "625/625 - 2s - loss: 0.1505 - accuracy: 0.9405 - val_loss: 1.4300 - val_accuracy: 0.5943\n",
            "Epoch 27/30\n",
            "625/625 - 2s - loss: 0.1470 - accuracy: 0.9426 - val_loss: 1.4453 - val_accuracy: 0.5923\n",
            "Epoch 28/30\n",
            "625/625 - 2s - loss: 0.1477 - accuracy: 0.9419 - val_loss: 1.4544 - val_accuracy: 0.5943\n",
            "Epoch 29/30\n",
            "625/625 - 2s - loss: 0.1445 - accuracy: 0.9439 - val_loss: 1.4819 - val_accuracy: 0.5908\n",
            "Epoch 30/30\n",
            "625/625 - 2s - loss: 0.1461 - accuracy: 0.9426 - val_loss: 1.5020 - val_accuracy: 0.5856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXeJArq-jAcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(s):\n",
        "  token.fit_on_texts(s)\n",
        "  sq=token.texts_to_sequences(s)\n",
        "  sp=pad_sequences(sq,maxlen=32,padding='post',truncating='post')\n",
        "\n",
        "  prob=model.predict(sp)\n",
        "  \n",
        "  if(prob>0.6):\n",
        "    print(\"Given sentence is sarcastic Don't die out of it\")\n",
        "  else:\n",
        "    print('Take it seriously duh')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-V5UBJOkOK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4544dd93-772c-4a59-f071-1c6e7fc3836e"
      },
      "source": [
        "sen=['cows lose thier job as milk prices drop']\n",
        "predict(sen)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.7294824]]\n",
            "Given sentence is sarcastic Don't die out of it\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}